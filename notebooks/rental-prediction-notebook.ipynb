{"cells":[{"cell_type":"markdown","metadata":{"id":"intro"},"source":["# Rental Price Prediction Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imports"},"outputs":[],"source":["!pip install xgboost lightgbm scikit-learn pandas numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"libraries"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n","from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n","from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n","import xgboost as xgb\n","from lightgbm import LGBMRegressor\n","import time\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imputer_classes"},"outputs":[],"source":["class DummyImputer:\n","    def fit_transform(self, X):\n","        return X\n","    def transform(self, X):\n","        return X\n","\n","class ImputationMethods:\n","    def __init__(self, random_state=42):\n","        self.random_state = random_state\n","        \n","    def get_imputers(self):\n","        return {\n","            'no_imputation': {\n","                'numeric': DummyImputer(),\n","                'categorical': DummyImputer()\n","            },\n","            'simple_mean': self._create_simple_mean_imputer(),\n","            'advanced_iterative': self._create_advanced_iterative_imputer()\n","        }\n","\n","    def _create_simple_mean_imputer(self):\n","        return {\n","            'numeric': SimpleImputer(strategy='mean'),\n","            'categorical': SimpleImputer(strategy='most_frequent')\n","        }\n","    \n","    def _create_advanced_iterative_imputer(self):\n","        return {\n","            'numeric': IterativeImputer(\n","                estimator=RandomForestRegressor(n_estimators=100, random_state=self.random_state),\n","                random_state=self.random_state\n","            ),\n","            'categorical': SimpleImputer(strategy='most_frequent')\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"model_functions"},"outputs":[],"source":["def get_models(random_state=42):\n","    return {\n","        'xgboost': xgb.XGBRegressor(\n","            n_estimators=500,\n","            max_depth=7,\n","            learning_rate=0.05,\n","            subsample=0.8,\n","            random_state=random_state\n","        ),\n","        'lightgbm': LGBMRegressor(\n","            n_estimators=500,\n","            num_leaves=31,\n","            learning_rate=0.05,\n","            random_state=random_state\n","        )\n","    }\n","\n","def get_optimized_models(random_state=42):\n","    return {\n","        'xgboost_optimized': xgb.XGBRegressor(\n","            n_estimators=500,\n","            max_depth=8,\n","            learning_rate=0.05,\n","            subsample=0.9,\n","            random_state=random_state\n","        )\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pipeline_class"},"outputs":[],"source":["class ModelPipeline:\n","    def __init__(self, imputation_methods, prediction_models, random_state=42):\n","        self.random_state = random_state\n","        self.imputation_methods = imputation_methods\n","        self.prediction_models = prediction_models\n","        self.results = {}\n","        \n","    def impute_data(self, X, numeric_features, categorical_features, imputer_dict, fit_imputer=True):\n","        encoded_cols = [col for col in X.columns if col.startswith('quarter_')]\n","        X_numeric = X[numeric_features].copy() if len(numeric_features) > 0 else pd.DataFrame()\n","        X_categorical = X[categorical_features].copy() if len(categorical_features) > 0 else pd.DataFrame()\n","\n","        if len(numeric_features) > 0:\n","            if fit_imputer:\n","                X_numeric = pd.DataFrame(\n","                    imputer_dict['numeric'].fit_transform(X_numeric),\n","                    columns=numeric_features,\n","                    index=X.index\n","                )\n","            else:\n","                X_numeric = pd.DataFrame(\n","                    imputer_dict['numeric'].transform(X_numeric),\n","                    columns=numeric_features,\n","                    index=X.index\n","                )\n","\n","        if len(categorical_features) > 0:\n","            if fit_imputer:\n","                X_categorical = pd.DataFrame(\n","                    imputer_dict['categorical'].fit_transform(X_categorical),\n","                    columns=categorical_features,\n","                    index=X.index\n","                )\n","            else:\n","                X_categorical = pd.DataFrame(\n","                    imputer_dict['categorical'].transform(X_categorical),\n","                    columns=categorical_features,\n","                    index=X.index\n","                )\n","\n","        if encoded_cols:\n","            X_encoded = X[encoded_cols].copy()\n","            return pd.concat([X_numeric, X_categorical, X_encoded], axis=1)\n","        else:\n","            return pd.concat([X_numeric, X_categorical], axis=1)\n","\n","    def run_pipeline(self, X_train, y_train, X_test, numeric_features, categorical_features):\n","        results = {}\n","        \n","        for imp_name, imputer in self.imputation_methods.items():\n","            print(f\"\\nProcessing with {imp_name} imputation...\")\n","            \n","            X_train_imputed = self.impute_data(X_train, numeric_features, categorical_features, imputer, True)\n","            X_test_imputed = self.impute_data(X_test, numeric_features, categorical_features, imputer, False)\n","\n","            for model_name, model in self.prediction_models.items():\n","                key = f\"{imp_name}_{model_name}\"\n","                print(f\"Training {key}...\")\n","                \n","                pipeline = Pipeline([\n","                    ('scaler', StandardScaler()),\n","                    ('model', model)\n","                ])\n","                \n","                cv_scores = cross_val_score(pipeline, X_train_imputed, y_train, \n","                                        cv=5, scoring='neg_root_mean_squared_error')\n","                \n","                pipeline.fit(X_train_imputed, y_train)\n","                test_predictions = pipeline.predict(X_test_imputed)\n","                \n","                results[key] = {\n","                    'cv_scores': -cv_scores,\n","                    'cv_rmse_mean': -cv_scores.mean(),\n","                    'cv_rmse_std': cv_scores.std(),\n","                    'test_predictions': test_predictions,\n","                    'model': pipeline\n","                }\n","                \n","                print(f\"Completed {key} - CV RMSE: {-cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n","        \n","        return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"utility_functions"},"outputs":[],"source":["def load_data(train_path, test_path):\n","    train_df = pd.read_csv(train_path)\n","    test_df = pd.read_csv(test_path)\n","    \n","    for name, df in [(\"Training\", train_df), (\"Test\", test_df)]:\n","        missing_stats = df.isnull().sum()\n","        missing_percentages = (missing_stats / len(df)) * 100\n","        \n","        print(f\"\\n{name} Dataset Missing Value Statistics:\")\n","        for column in df.columns:\n","            if missing_stats[column] > 0:\n","                print(f\"{column}: {missing_stats[column]} missing values ({missing_percentages[column]:.2f}%)\")\n","    \n","    return train_df, test_df\n","\n","def prepare_data(df, target_column=None):\n","    if target_column and target_column in df.columns:\n","        X = df.drop(columns=[target_column])\n","        y = df[target_column]\n","    else:\n","        X = df\n","        y = None\n","        \n","    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n","    numeric_features = [col for col in numeric_features if not col.startswith('quarter_')]\n","    \n","    categorical_features = []\n","    return X, y, numeric_features, categorical_features\n","\n","def save_results(results, output_dir='predictions'):\n","    os.makedirs(output_dir, exist_ok=True)\n","    \n","    summary_data = []\n","    for approach_name, result in results.items():\n","        test_predictions_df = pd.DataFrame({\n","            'ID': range(1, len(result['test_predictions']) + 1),\n","            'TARGET': result['test_predictions']\n","        })\n","        test_predictions_df.to_csv(f'{output_dir}/{approach_name}_test_predictions.csv', index=False)\n","        \n","        summary_data.append({\n","            'approach': approach_name,\n","            'cv_rmse_mean': result['cv_rmse_mean'],\n","            'cv_rmse_std': result['cv_rmse_std']\n","        })\n","    \n","    summary_df = pd.DataFrame(summary_data)\n","    summary_df = summary_df.sort_values('cv_rmse_mean')\n","    summary_df.to_csv(f'{output_dir}/approach_comparison.csv', index=False)\n","    \n","    print(\"\\nApproach Comparison:\")\n","    print(summary_df.to_string(index=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"data_processing"},"outputs":[],"source":["def process_quarters(train_df, test_df):\n","    train_quarters = pd.get_dummies(train_df['quarter'], prefix='quarter')\n","    test_quarters = pd.get_dummies(test_df['quarter'], prefix='quarter')\n","    \n","    missing_in_train = set(test_quarters.columns) - set(train_quarters.columns)\n","    missing_in_test = set(train_quarters.columns) - set(test_quarters.columns)\n","    \n","    for col in missing_in_train:\n","        train_quarters[col] = 0\n","    for col in missing_in_test:\n","        test_quarters[col] = 0\n","        \n","    train_quarters = train_quarters[sorted(train_quarters.columns)]\n","    test_quarters = test_quarters[sorted(test_quarters.columns)]\n","    \n","    train_df = train_df.drop(columns=['quarter'])\n","    test_df = test_df.drop(columns=['quarter'])\n","    \n","    quarter_cols = sorted(train_quarters.columns)[1:]\n","    train_df = pd.concat([train_df, train_quarters[quarter_cols]], axis=1)\n","    test_df = pd.concat([test_df, test_quarters[quarter_cols]], axis=1)\n","    \n","    return train_df, test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"main_execution"},"outputs":[],"source":["# Main execution\n","train_df, test_df = load_data(\"pzn-rent-train-processed.csv\", \"pzn-rent-test-processed.csv\")\n","train_df, test_df = process_quarters(train_df, test_df)\n","\n","X_train, y_train, numeric_features, categorical_features = prepare_data(train_df, 'price')\n","X_test, _, _, _ = prepare_data(test_df)\n","\n","imputer = ImputationMethods()\n","imputation_methods = {\n","    'no_imputation': imputer.get_imputers()['no_imputation'],\n","    'simple_mean': imputer.get_imputers()['simple_mean'],\n","    'advanced_iterative': imputer.get_imputers()['advanced_iterative']\n","}\n","\n","base_models = get_models()\n","optimized_models = get_optimized_models()\n","\n","selected_models = {\n","    'xgboost': base_models['xgboost'],\n","    'lightgbm': base_models['lightgbm'],\n","    'xgboost_optimized': optimized_models['xgboost_optimized']\n","}\n","\n","pipeline = ModelPipeline(imputation_methods, selected_models)\n","results = pipeline.run_pipeline(X_train, y_train, X_test, numeric_features, categorical_features)\n","\n","save_results(results)"]}],"metadata":{"colab":{"name":"Rental_Price_Prediction.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}